{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa383d0a-b283-4772-bc05-fdaf9519e59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['JAVA_HOME'] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ['SPARK_HOME'] = \"/home/bdai/spark_work/spark-3.2.4-bin-hadoop3.2\"\n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"--jars /home/bdai/spark_work/rapids-4-spark_2.12-23.06.0.jar,/home/bdai/spark_work/cudf-23.06.0-cuda12.jar --master local[*] pyspark-shell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f533b06-99f6-443a-bc91-7cb9733a9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "import shutil\n",
    "import warnings\n",
    "import time\n",
    "import torch\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad44e98c-b2f1-4995-804f-1c7e8e59e22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timing(start):\n",
    "    print(f'Elapsed time: {time.time() - start:.2f} s')\n",
    "# start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc38141-ec20-4819-9f7b-ef2351bb7131",
   "metadata": {},
   "source": [
    "# Start Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dcd3f2c-e8ee-4a74-baf8-6bc4c10b3f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/01 09:32:48 WARN Utils: Your hostname, bdai-desktop resolves to a loopback address: 127.0.1.1; using 165.132.118.198 instead (on interface enp0s31f6)\n",
      "23/08/01 09:32:48 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "23/08/01 09:32:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/01 09:32:49 WARN RapidsPluginUtils: RAPIDS Accelerator 23.06.0 using cudf 23.06.0.\n",
      "23/08/01 09:32:49 WARN RapidsPluginUtils: RAPIDS Accelerator is enabled, to disable GPU support set `spark.rapids.sql.enabled` to false.\n",
      "23/08/01 09:32:49 WARN RapidsPluginUtils: spark.rapids.sql.explain is set to `NOT_ON_GPU`. Set it to 'NONE' to suppress the diagnostics logging about the query placement on the GPU.\n",
      "23/08/01 09:33:02 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:537)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\t... 3 more\n",
      "23/08/01 09:33:02 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:537)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/08/01 09:33:12 ERROR Inbox: Ignoring error\n",
      "java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:537)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "23/08/01 09:33:12 WARN Executor: Issue communicating with driver in heartbeater\n",
      "org.apache.spark.SparkException: Exception thrown in awaitResult: \n",
      "\tat org.apache.spark.util.ThreadUtils$.awaitResult(ThreadUtils.scala:301)\n",
      "\tat org.apache.spark.rpc.RpcTimeout.awaitResult(RpcTimeout.scala:75)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:103)\n",
      "\tat org.apache.spark.rpc.RpcEndpointRef.askSync(RpcEndpointRef.scala:87)\n",
      "\tat org.apache.spark.storage.BlockManagerMaster.registerBlockManager(BlockManagerMaster.scala:79)\n",
      "\tat org.apache.spark.storage.BlockManager.reregister(BlockManager.scala:636)\n",
      "\tat org.apache.spark.executor.Executor.reportHeartBeat(Executor.scala:1009)\n",
      "\tat org.apache.spark.executor.Executor.$anonfun$heartbeater$1(Executor.scala:212)\n",
      "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
      "\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2048)\n",
      "\tat org.apache.spark.Heartbeater$$anon$1.run(Heartbeater.scala:46)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)\n",
      "\tat java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "Caused by: java.lang.NullPointerException\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint.org$apache$spark$storage$BlockManagerMasterEndpoint$$register(BlockManagerMasterEndpoint.scala:537)\n",
      "\tat org.apache.spark.storage.BlockManagerMasterEndpoint$$anonfun$receiveAndReply$1.applyOrElse(BlockManagerMasterEndpoint.scala:119)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.$anonfun$process$1(Inbox.scala:103)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.safelyCall(Inbox.scala:213)\n",
      "\tat org.apache.spark.rpc.netty.Inbox.process(Inbox.scala:100)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop.org$apache$spark$rpc$netty$MessageLoop$$receiveLoop(MessageLoop.scala:75)\n",
      "\tat org.apache.spark.rpc.netty.MessageLoop$$anon$1.run(MessageLoop.scala:41)\n",
      "\tat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)\n",
      "\tat java.util.concurrent.FutureTask.run(FutureTask.java:266)\n",
      "\t... 3 more\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 27.56 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkTrain').config('spark.plugins','com.nvidia.spark.SQLPlugin').config(\"spark.driver.memory\", \"15g\").getOrCreate()\n",
    "spark.sparkContext.addPyFile('/home/bdai/spark_work/rapids-4-spark_2.12-23.06.0.jar')\n",
    "spark.sparkContext.addPyFile('/home/bdai/spark_work/cudf-23.06.0-cuda12.jar')\n",
    "spark.conf.set('spark.rapids.sql.enabled','true')\n",
    "spark.conf.set('spark.rapids.sql.incompatibleOps.enabled', 'true')\n",
    "spark.conf.set('spark.rapids.sql.format.csv.read.enabled', 'true')\n",
    "spark.conf.set('spark.rapids.sql.format.csv.enabled', 'true')\n",
    "\n",
    "timing(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa6673-00b3-4ce6-80d1-4783fd5ba85a",
   "metadata": {},
   "source": [
    "# 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87460605-bc29-430d-b789-2d9d39c869b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_path = \"/home/bdai/spark_work/spark-warehouse/covid_train_binary\"\n",
    "test_image_path = \"/home/bdai/spark_work/spark-warehouse/covid_test_binary\"\n",
    "cache_path = \"file:///home/bdai/spark_work/petastorm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e52230e-c6c5-4097-b238-92d8e2033ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 2.70 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "train_df = spark.read.parquet(train_image_path)\n",
    "df_test = spark.read.parquet(test_image_path)\n",
    "\n",
    "df_train, df_val = train_df.randomSplit([0.8, 0.2], seed=12345)\n",
    "\n",
    "timing(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a00087-2e8e-4a7f-a9e9-a40a088b939d",
   "metadata": {},
   "source": [
    "# 2. Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ed78f42-f3bd-43be-9660-d1a3d1eb3f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from petastorm.spark import SparkDatasetConverter, make_spark_converter\n",
    "from petastorm import TransformSpec\n",
    "\n",
    "image_shape = (3, 224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9fcc8-79ef-4c8b-a48e-991b3602331c",
   "metadata": {},
   "source": [
    "## 1) Cache the Spark DataFrame using Petastorm Spark converter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38f58c73-0a49-40fd-a37f-0795ca1061aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting floating-point columns to float32\n",
      "23/08/01 09:33:57 WARN GpuOverrides: \n",
      "    !Exec <SampleExec> cannot run on GPU because unsupported data types in output: BinaryType [content#3]; unsupported data types in input: BinaryType [content#3]\n",
      "      !Exec <SortExec> cannot run on GPU because not all expressions can be replaced\n",
      "        @Expression <SortOrder> path#0 ASC NULLS FIRST could run on GPU\n",
      "          @Expression <AttributeReference> path#0 could run on GPU\n",
      "        @Expression <SortOrder> file_name#1 ASC NULLS FIRST could run on GPU\n",
      "          @Expression <AttributeReference> file_name#1 could run on GPU\n",
      "        @Expression <SortOrder> size#2 ASC NULLS FIRST could run on GPU\n",
      "          @Expression <AttributeReference> size#2 could run on GPU\n",
      "        !Expression <SortOrder> content#3 ASC NULLS FIRST cannot run on GPU because input expression AttributeReference content#3 (BinaryType is not supported); expression SortOrder content#3 ASC NULLS FIRST produces an unsupported type BinaryType\n",
      "          @Expression <AttributeReference> content#3 could run on GPU\n",
      "        @Expression <SortOrder> class#4 ASC NULLS FIRST could run on GPU\n",
      "          @Expression <AttributeReference> class#4 could run on GPU\n",
      "        @Expression <SortOrder> label#5 ASC NULLS FIRST could run on GPU\n",
      "          @Expression <AttributeReference> label#5 could run on GPU\n",
      "\n",
      "Converting floating-point columns to float32                                    \n",
      "23/08/01 09:36:52 WARN GpuOverrides: \n",
      "    !Exec <SampleExec> cannot run on GPU because unsupported data types in output: BinaryType [content#3]; unsupported data types in input: BinaryType [content#3]\n",
      "      !Exec <SortExec> cannot run on GPU because not all expressions can be replaced\n",
      "        @Expression <SortOrder> path#0 ASC NULLS FIRST could run on GPU\n",
      "          @Expression <AttributeReference> path#0 could run on GPU\n",
      "        @Expression <SortOrder> file_name#1 ASC NULLS FIRST could run on GPU\n",
      "          @Expression <AttributeReference> file_name#1 could run on GPU\n",
      "        @Expression <SortOrder> size#2 ASC NULLS FIRST could run on GPU\n",
      "          @Expression <AttributeReference> size#2 could run on GPU\n",
      "        !Expression <SortOrder> content#3 ASC NULLS FIRST cannot run on GPU because input expression AttributeReference content#3 (BinaryType is not supported); expression SortOrder content#3 ASC NULLS FIRST produces an unsupported type BinaryType\n",
      "          @Expression <AttributeReference> content#3 could run on GPU\n",
      "        @Expression <SortOrder> class#4 ASC NULLS FIRST could run on GPU\n",
      "          @Expression <AttributeReference> class#4 could run on GPU\n",
      "        @Expression <SortOrder> label#5 ASC NULLS FIRST could run on GPU\n",
      "          @Expression <AttributeReference> label#5 could run on GPU\n",
      "\n",
      "The median size 19847187 B (< 50 MB) of the parquet files is too small. Total size: 3447299583 B. Increase the median file size by calling df.repartition(n) or df.coalesce(n), which might help improve the performance. Parquet files: file:///home/bdai/spark_work/petastorm/20230801093652-appid-local-1690849969354-899517da-6b4e-469d-a945-6e2e7068c4fd/part-00130-f5cd499d-55dc-4974-8c5a-5198d0530475-c000.parquet, ...\n",
      "Converting floating-point columns to float32\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 23912, val: 6074, test : 400\n",
      "Elapsed time: 291.73 s\n"
     ]
    }
   ],
   "source": [
    "# Set a cache directory on DBFS FUSE for intermediate data.\n",
    "start = time.time()\n",
    "\n",
    "spark.conf.set(SparkDatasetConverter.PARENT_CACHE_DIR_URL_CONF, cache_path)\n",
    "\n",
    "converter_train = make_spark_converter(df_train)\n",
    "converter_val = make_spark_converter(df_val)\n",
    "converter_test = make_spark_converter(df_test)\n",
    "\n",
    "print(f\"train: {len(converter_train)}, val: {len(converter_val)}, test : {len(converter_test)}\")\n",
    "\n",
    "timing(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09948a01-db59-46dd-93de-d14a5e22c932",
   "metadata": {},
   "source": [
    "## 2) Preprocess images\n",
    "Before feeding the dataset into the model, we need to decode the raw image bytes and apply standard ImageNet transforms. We recommend not doing this transformation on the Spark DataFrame since that will substantially increase the size of the intermediate files and might harm the performance. Instead, we recommend doing this transformation in a TransformSpec function in petastorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7118c5e-6552-4a6c-bb20-744f860d841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(content):\n",
    "    image = Image.open(io.BytesIO(content)).resize([image_shape[1],image_shape[2]])\n",
    "    transformers = [transforms.Lambda(lambda image: image.convert('RGB'))]\n",
    "    transformers.extend([transforms.ToTensor()])\n",
    "    trans = transforms.Compose(transformers)\n",
    "    image_arr = trans(image)\n",
    "    return image_arr.numpy()\n",
    "    \n",
    "\n",
    "def transform_row(pd_batch):\n",
    "  \"\"\"\n",
    "  The input and output of this function must be pandas dataframes.\n",
    "  \"\"\"\n",
    "  pd_batch['features'] = pd_batch['content'].map(lambda x: preprocess(x))\n",
    "  pd_batch['label'] = pd_batch['label'].map(lambda x: int(x))\n",
    "  pd_batch = pd_batch.drop(labels=['content'], axis=1)\n",
    "  return pd_batch[['features', 'label']]\n",
    "\n",
    "def get_transform_spec():\n",
    "  # Note that the output shape of the `TransformSpec` is not automatically known by petastorm, \n",
    "  # so we need to specify the shape for new columns in `edit_fields` and specify the order of \n",
    "  # the output columns in `selected_fields`.\n",
    "  return TransformSpec(transform_row, \n",
    "                       edit_fields=[('features', np.float32, image_shape, False)], \n",
    "                       selected_fields=['features', 'label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487492df-2a5b-4934-8c15-bfd720e3d2bc",
   "metadata": {},
   "source": [
    "## 3) Examining execution time for dataloading and transorming a batch    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0685da20-4eb8-49e6-be2c-1b94f478fd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 5.36 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "with converter_train.make_torch_dataloader(transform_spec=get_transform_spec(), batch_size=16) as train_dataloader:\n",
    "    train_dataloader_iter = iter(train_dataloader)\n",
    "    for idx, batch in enumerate(train_dataloader_iter):\n",
    "        if idx == 1: break\n",
    "\n",
    "timing(start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b85923-a6ba-445a-aa32-1444e4bdeecb",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe5d367-85ec-4fa0-8fff-709042c6b4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613a10f4-d7e2-485d-b837-31d42cc0b06c",
   "metadata": {},
   "source": [
    "## 1) Get the model ResNet from torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31319536-7a2f-443c-b956-a97e82a220fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(lr=0.001):\n",
    "  # Load a MobileNetV2 model from torchvision\n",
    "  model = torchvision.models.resnet50(pretrained=True)\n",
    "  # Freeze parameters in the feature extraction layers\n",
    "  for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "  # Add a new classifier layer for transfer learning\n",
    "  num_ftrs = model.fc.in_features\n",
    "  # Parameters of newly constructed modules have requires_grad=True by default\n",
    "  model.fc = torch.nn.Linear(num_ftrs, 2)\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf3592c-c981-47d0-9b96-d1c1f0e9bb5e",
   "metadata": {},
   "source": [
    "## 2) Define the train and evaluate function for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7416cea7-290b-4d47-8deb-bb79167bf84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, criterion, optimizer, scheduler, \n",
    "                    train_dataloader_iter, steps_per_epoch, epoch, \n",
    "                    device):\n",
    "  model.train()  # Set model to training mode\n",
    "\n",
    "  # statistics\n",
    "  running_loss = 0.0\n",
    "  running_corrects = 0\n",
    "\n",
    "  # Iterate over the data for one epoch.\n",
    "  for step in range(steps_per_epoch):\n",
    "    pd_batch = next(train_dataloader_iter)\n",
    "    inputs, labels = pd_batch['features'].to(device), pd_batch['label'].to(device)\n",
    "    \n",
    "    # Track history in training\n",
    "    with torch.set_grad_enabled(True):\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # forward\n",
    "      outputs = model(inputs)\n",
    "      _, preds = torch.max(outputs, 1)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # backward + optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "    # statistics\n",
    "    running_loss += loss.item() * inputs.size(0)\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "  \n",
    "  scheduler.step()\n",
    "\n",
    "  epoch_loss = running_loss / (steps_per_epoch * BATCH_SIZE)\n",
    "  epoch_acc = running_corrects.double() / (steps_per_epoch * BATCH_SIZE)\n",
    "\n",
    "  print('Train Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "  return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate(model, criterion, val_dataloader_iter, validation_steps, device, \n",
    "             metric_agg_fn=None):\n",
    "  model.eval()  # Set model to evaluate mode\n",
    "\n",
    "  # statistics\n",
    "  running_loss = 0.0\n",
    "  running_corrects = 0\n",
    "\n",
    "  # Iterate over all the validation data.\n",
    "  for step in range(validation_steps):\n",
    "    pd_batch = next(val_dataloader_iter)\n",
    "    inputs, labels = pd_batch['features'].to(device), pd_batch['label'].to(device)\n",
    "\n",
    "    # Do not track history in evaluation to save memory\n",
    "    with torch.set_grad_enabled(False):\n",
    "      # forward\n",
    "      outputs = model(inputs)\n",
    "      _, preds = torch.max(outputs, 1)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "    # statistics\n",
    "    running_loss += loss.item()\n",
    "    running_corrects += torch.sum(preds == labels.data)\n",
    "  \n",
    "  # The losses are averaged across observations for each minibatch.\n",
    "  epoch_loss = running_loss / validation_steps\n",
    "  epoch_acc = running_corrects.double() / (validation_steps * BATCH_SIZE)\n",
    "  \n",
    "  # metric_agg_fn is used in the distributed training to aggregate the metrics on all workers\n",
    "  if metric_agg_fn is not None:\n",
    "    epoch_loss = metric_agg_fn(epoch_loss, 'avg_loss')\n",
    "    epoch_acc = metric_agg_fn(epoch_acc, 'avg_acc')\n",
    "\n",
    "  print('Validation Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "  return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46242cb1-f02d-4940-9aae-a265ad4340da",
   "metadata": {},
   "source": [
    "## 3) Train and evaluate the model on the local machine\n",
    "Use converter.make_torch_dataloader(...) to create the dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d07be4-4413-4268-b201-2b3cd45d3925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "NUM_EPOCHS = 2\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0927b0d-6066-4ef2-a207-d53afd7dc00f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.80 GiB total capacity; 68.83 MiB already allocated; 38.69 MiB free; 78.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 30\u001b[0m\n\u001b[1;32m     25\u001b[0m             train_loss, train_acc \u001b[38;5;241m=\u001b[39m train_one_epoch(model, criterion, optimizer, exp_lr_scheduler, \n\u001b[1;32m     26\u001b[0m                                                   train_dataloader_iter, steps_per_epoch, epoch, \n\u001b[1;32m     27\u001b[0m                                                   device)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loss\n\u001b[0;32m---> 30\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 5\u001b[0m, in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(lr)\u001b[0m\n\u001b[1;32m      2\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m get_model(lr\u001b[38;5;241m=\u001b[39mlr)\n\u001b[0;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Only parameters of final layer are being optimized.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spark_env/lib/python3.9/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    923\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 927\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/spark_env/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spark_env/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spark_env/lib/python3.9/site-packages/torch/nn/modules/module.py:579\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 579\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    584\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    590\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/spark_env/lib/python3.9/site-packages/torch/nn/modules/module.py:602\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 602\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/spark_env/lib/python3.9/site-packages/torch/nn/modules/module.py:925\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    924\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 3.80 GiB total capacity; 68.83 MiB already allocated; 38.69 MiB free; 78.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "def train_and_evaluate(lr=0.001):\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    model = get_model(lr=lr)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Only parameters of final layer are being optimized.\n",
    "    optimizer = torch.optim.SGD(model.fc.parameters(), lr=lr, momentum=0.9)\n",
    "    \n",
    "    # Decay LR by a factor of 0.1 every 7 epochs\n",
    "    exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "    \n",
    "    with converter_test.make_torch_dataloader(transform_spec=get_transform_spec(), batch_size=BATCH_SIZE) as train_dataloader:\n",
    "    \n",
    "        train_dataloader_iter = iter(train_dataloader)\n",
    "        steps_per_epoch = len(converter_test) // BATCH_SIZE\n",
    "        \n",
    "        \n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            print('Epoch {}/{}'.format(epoch + 1, NUM_EPOCHS))\n",
    "            print('-' * 10)\n",
    "            \n",
    "            train_loss, train_acc = train_one_epoch(model, criterion, optimizer, exp_lr_scheduler, \n",
    "                                                  train_dataloader_iter, steps_per_epoch, epoch, \n",
    "                                                  device)\n",
    "    return train_loss\n",
    "\n",
    "loss = train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eeadde-d71c-4020-b59b-7fb3a5ff4282",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = get_model(lr=lr)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Only parameters of final layer are being optimized.\n",
    "optimizer = torch.optim.SGD(model.classifier[1].parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "with converter_train.make_torch_dataloader(transform_spec=get_transform_spec(), \n",
    "                                         batch_size=BATCH_SIZE) as train_dataloader, \\\n",
    "   converter_val.make_torch_dataloader(transform_spec=get_transform_spec(), \n",
    "                                       batch_size=BATCH_SIZE) as val_dataloader:\n",
    "\n",
    "    train_dataloader_iter = iter(train_dataloader)\n",
    "    steps_per_epoch = len(converter_train) // BATCH_SIZE\n",
    "    \n",
    "    val_dataloader_iter = iter(val_dataloader)\n",
    "    validation_steps = max(1, len(converter_val) // BATCH_SIZE)\n",
    "    \n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "      print('Epoch {}/{}'.format(epoch + 1, NUM_EPOCHS))\n",
    "      print('-' * 10)\n",
    "    \n",
    "      train_loss, train_acc = train_one_epoch(model, criterion, optimizer, exp_lr_scheduler, \n",
    "                                              train_dataloader_iter, steps_per_epoch, epoch, \n",
    "                                              device)\n",
    "      val_loss, val_acc = evaluate(model, criterion, val_dataloader_iter, validation_steps, device)\n",
    "\n",
    "loss = train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "88d71bce-b884-475f-a815-89af18812102",
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(train_dataloader_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "11ec9ad4-805e-48b7-989b-47df85d8393f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/fs_utils.py:88: FutureWarning: pyarrow.localfs is deprecated as of 2.0.0, please use pyarrow.fs.LocalFileSystem instead.\n",
      "  self._filesystem = pyarrow.localfs\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/etl/dataset_metadata.py:402: FutureWarning: Passing 'use_legacy_dataset=True' to get the legacy behaviour is deprecated as of pyarrow 11.0.0, and the legacy implementation will be removed in a future version. The legacy behaviour was still chosen because a deprecated 'pyarrow.filesystem' filesystem was specified (use the filesystems from pyarrow.fs instead).\n",
      "  dataset = pq.ParquetDataset(path_or_paths, filesystem=fs, validate_schema=False, metadata_nthreads=10)\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/etl/dataset_metadata.py:402: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
      "  dataset = pq.ParquetDataset(path_or_paths, filesystem=fs, validate_schema=False, metadata_nthreads=10)\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/etl/dataset_metadata.py:362: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
      "  if not dataset.common_metadata:\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/reader.py:420: FutureWarning: Passing 'use_legacy_dataset=True' to get the legacy behaviour is deprecated as of pyarrow 11.0.0, and the legacy implementation will be removed in a future version. The legacy behaviour was still chosen because a deprecated 'pyarrow.filesystem' filesystem was specified (use the filesystems from pyarrow.fs instead).\n",
      "  self.dataset = pq.ParquetDataset(dataset_path, filesystem=pyarrow_filesystem,\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/reader.py:420: FutureWarning: Specifying the 'metadata_nthreads' argument is deprecated as of pyarrow 8.0.0, and the argument will be removed in a future version\n",
      "  self.dataset = pq.ParquetDataset(dataset_path, filesystem=pyarrow_filesystem,\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/unischema.py:317: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
      "  meta = parquet_dataset.pieces[0].get_metadata()\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/unischema.py:321: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  for partition in (parquet_dataset.partitions or []):\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/unischema.py:347: UserWarning: Column 'size' has an unsupported field StructType(struct<width: int32, height: int32>). Ignoring...\n",
      "  warnings.warn('Column %r has an unsupported field %r. Ignoring...'\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/etl/dataset_metadata.py:253: FutureWarning: 'ParquetDataset.metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
      "  metadata = dataset.metadata\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/etl/dataset_metadata.py:254: FutureWarning: 'ParquetDataset.common_metadata' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
      "  common_metadata = dataset.common_metadata\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.pieces' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.fragments' attribute instead.\n",
      "  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/etl/dataset_metadata.py:350: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  futures_list = [thread_pool.submit(_split_piece, piece, dataset.fs.open) for piece in dataset.pieces]\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/etl/dataset_metadata.py:334: FutureWarning: ParquetDatasetPiece is deprecated as of pyarrow 5.0.0 and will be removed in a future version.\n",
      "  return [pq.ParquetDatasetPiece(piece.path, open_file_func=fs_open,\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py:132: FutureWarning: Passing 'use_legacy_dataset=True' to get the legacy behaviour is deprecated as of pyarrow 11.0.0, and the legacy implementation will be removed in a future version. The legacy behaviour was still chosen because a deprecated 'pyarrow.filesystem' filesystem was specified (use the filesystems from pyarrow.fs instead).\n",
      "  self._dataset = pq.ParquetDataset(\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py:140: FutureWarning: 'ParquetDataset.fs' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.filesystem' attribute instead.\n",
      "  parquet_file = ParquetFile(self._dataset.fs.open(piece.path))\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py:288: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  partition_names = self._dataset.partitions.partition_names if self._dataset.partitions else set()\n",
      "/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py:291: FutureWarning: 'ParquetDataset.partitions' attribute is deprecated as of pyarrow 5.0.0 and will be removed in a future version. Specify 'use_legacy_dataset=False' while constructing the ParquetDataset, and then use the '.partitioning' attribute instead.\n",
      "  table = piece.read(columns=column_names - partition_names, partitions=self._dataset.partitions)\n",
      "Worker 2 terminated: unexpected exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/workers_pool/thread_pool.py\", line 62, in run\n",
      "    self._worker_impl.process(*args, **kargs)\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 163, in process\n",
      "    all_cols = self._local_cache.get(cache_key,\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/cache.py\", line 39, in get\n",
      "    return fill_cache_func()\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 164, in <lambda>\n",
      "    lambda: self._load_rows(parquet_file, piece, shuffle_row_drop_partition))\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 219, in _load_rows\n",
      "    transformed_result[field.name] = transformed_result[field.name] \\\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/pandas/core/series.py\", line 4397, in map\n",
      "    new_values = self._map_values(arg, na_action=na_action)\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/pandas/core/base.py\", line 924, in _map_values\n",
      "    new_values = map_f(values, mapper)\n",
      "  File \"pandas/_libs/lib.pyx\", line 2834, in pandas._libs.lib.map_infer\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 220, in <lambda>\n",
      "    .map(lambda x, f=field: self._check_shape_and_ravel(x, f))\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 178, in _check_shape_and_ravel\n",
      "    raise ValueError('field {name} must be the shape {shape}'\n",
      "ValueError: field features must be the shape (3, 224, 224)\n",
      "Worker 1 terminated: unexpected exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/workers_pool/thread_pool.py\", line 62, in run\n",
      "    self._worker_impl.process(*args, **kargs)\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 163, in process\n",
      "    all_cols = self._local_cache.get(cache_key,\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/cache.py\", line 39, in get\n",
      "    return fill_cache_func()\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 164, in <lambda>\n",
      "    lambda: self._load_rows(parquet_file, piece, shuffle_row_drop_partition))\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 219, in _load_rows\n",
      "    transformed_result[field.name] = transformed_result[field.name] \\\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/pandas/core/series.py\", line 4397, in map\n",
      "    new_values = self._map_values(arg, na_action=na_action)\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/pandas/core/base.py\", line 924, in _map_values\n",
      "    new_values = map_f(values, mapper)\n",
      "  File \"pandas/_libs/lib.pyx\", line 2834, in pandas._libs.lib.map_infer\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 220, in <lambda>\n",
      "    .map(lambda x, f=field: self._check_shape_and_ravel(x, f))\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 178, in _check_shape_and_ravel\n",
      "    raise ValueError('field {name} must be the shape {shape}'\n",
      "ValueError: field features must be the shape (3, 224, 224)\n",
      "Worker 3 terminated: unexpected exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/workers_pool/thread_pool.py\", line 62, in run\n",
      "    self._worker_impl.process(*args, **kargs)\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 163, in process\n",
      "    all_cols = self._local_cache.get(cache_key,\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/cache.py\", line 39, in get\n",
      "    return fill_cache_func()\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 164, in <lambda>\n",
      "    lambda: self._load_rows(parquet_file, piece, shuffle_row_drop_partition))\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 219, in _load_rows\n",
      "    transformed_result[field.name] = transformed_result[field.name] \\\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/pandas/core/series.py\", line 4397, in map\n",
      "    new_values = self._map_values(arg, na_action=na_action)\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/pandas/core/base.py\", line 924, in _map_values\n",
      "    new_values = map_f(values, mapper)\n",
      "  File \"pandas/_libs/lib.pyx\", line 2834, in pandas._libs.lib.map_infer\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 220, in <lambda>\n",
      "    .map(lambda x, f=field: self._check_shape_and_ravel(x, f))\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 178, in _check_shape_and_ravel\n",
      "    raise ValueError('field {name} must be the shape {shape}'\n",
      "ValueError: field features must be the shape (3, 224, 224)\n",
      "Worker 0 terminated: unexpected exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/workers_pool/thread_pool.py\", line 62, in run\n",
      "    self._worker_impl.process(*args, **kargs)\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 163, in process\n",
      "    all_cols = self._local_cache.get(cache_key,\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/cache.py\", line 39, in get\n",
      "    return fill_cache_func()\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 164, in <lambda>\n",
      "    lambda: self._load_rows(parquet_file, piece, shuffle_row_drop_partition))\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 219, in _load_rows\n",
      "    transformed_result[field.name] = transformed_result[field.name] \\\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/pandas/core/series.py\", line 4397, in map\n",
      "    new_values = self._map_values(arg, na_action=na_action)\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/pandas/core/base.py\", line 924, in _map_values\n",
      "    new_values = map_f(values, mapper)\n",
      "  File \"pandas/_libs/lib.pyx\", line 2834, in pandas._libs.lib.map_infer\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 220, in <lambda>\n",
      "    .map(lambda x, f=field: self._check_shape_and_ravel(x, f))\n",
      "  File \"/home/bdai/anaconda3/envs/spark_env/lib/python3.9/site-packages/petastorm/arrow_reader_worker.py\", line 178, in _check_shape_and_ravel\n",
      "    raise ValueError('field {name} must be the shape {shape}'\n",
      "ValueError: field features must be the shape (3, 224, 224)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'TorchDatasetContextManager' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m converter_train\u001b[38;5;241m.\u001b[39mmake_torch_dataloader(transform_spec\u001b[38;5;241m=\u001b[39mget_transform_spec(), \n\u001b[1;32m      2\u001b[0m                                          batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE) \u001b[38;5;28;01mas\u001b[39;00m train_dataloader:\n\u001b[0;32m----> 3\u001b[0m     train_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'TorchDatasetContextManager' object is not iterable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6c60b3f0-05c7-4380-87de-8cbbc482e1f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_iter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_iter\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_iter' is not defined"
     ]
    }
   ],
   "source": [
    "train_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae3d1dc-f47d-4db5-9d41-973ac55c3c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
